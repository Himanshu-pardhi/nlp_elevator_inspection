{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a csv file for all codes (labels) \n",
    "all_df = pd.DataFrame()\n",
    "path = 'C:\\\\Users\\\\user\\\\Desktop\\\\AI projects\\\\nlp_project_files\\\\'\n",
    "for file in os.listdir(r'C:\\Users\\user\\Desktop\\AI projects\\nlp_project_files'):\n",
    "    if  file != 'kone_classification.json':\n",
    "        df = pd.read_csv(f'{path}{file}')\n",
    "        all_df = pd.concat([all_df, df], ignore_index=True)\n",
    "\n",
    "print(all_df.shape)\n",
    "all_df.to_csv(f'{path}complete_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the jesonfile as dataframe\n",
    "json_file = \"C:\\\\Users\\\\user\\\\Desktop\\\\AI projects\\\\nlp_project_files\\\\kone_classification.json\"\n",
    "with open(json_file) as f:\n",
    "    data = json.load(f)\n",
    "    df_json=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The description of the dataset is: \\n\",df_json.describe())\n",
    "print(\"The number of labels in the dataset is: \",df_json['label'].nunique())\n",
    "# count the rows for each language\n",
    "df_json.groupby('culture').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the maximum and minimum frequent for each label\n",
    "df_json.groupby('label').count().sort_values(by=['text'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the training source and drop the workflow\n",
    "df_json_training= df_json.loc[df_json['source']== 'TRAINING',:]\n",
    "df_json_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the duplicated rows\n",
    "duplicateRows = df_json_training[df_json_training.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated rows\n",
    "df_json_training.drop_duplicates()\n",
    "# df_json_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the French culture\n",
    "df_json_training_fr = df_json_training.loc[df_json_training['culture']=='fr-fr',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_json_training_fr['document_id'].nunique())\n",
    "print(df_json_training_fr['annotation_id'].nunique())\n",
    "print('the unique number of labels is: ',df_json_training_fr['label'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the maximum and minimum frequent for each label\n",
    "df_json_training_fr.groupby('label').count().sort_values(by=['text'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_training_fr['text'] = df_json_training_fr['text'].str.lower()\n",
    "df_json_training_fr['text'] = df_json_training_fr['text'].str.replace(r\"[(),.:*\\'\\\"\\n]\", \" \", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json_training_fr['text'].iloc[199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_stopwords = spacy.lang.fr.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df_json_training_fr['text'].iloc[18])\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sent = []\n",
    "for word in doc:\n",
    "    if word.is_stop == False:\n",
    "      filtered_sent.append(word)\n",
    "print(filtered_sent)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\user\\\\Desktop\\\\AI projects\\\\nlp_project_files\\\\'\n",
    "\n",
    "df = pd.read_csv(f'{path}CAR-Grid view.csv')\n",
    "print('CAR-Grid view.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{path}COUNTERWEIGHT-Grid view.csv')\n",
    "print('COUNTERWEIGHT-Grid view.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{path}DOCUMENTS-Grid view.csv')\n",
    "print('DOCUMENTS-Grid view.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{path}DOORS-Grid view.csv')\n",
    "print('DOORS-Grid view.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{path}HYDRAULICS-Grid view.csv')\n",
    "print('HYDRAULICS-Grid view.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{path}MACHINERY ROOM-Grid view.csv')\n",
    "print('MACHINERY ROOM-Grid view.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{path}SHAFT-Grid view.csv')\n",
    "print('SHAFT-Grid view.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{path}SIGNALISATION-Grid view.csv')\n",
    "print('SIGNALISATION-Grid view.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "319cceb38ce3abb27b8cff5600f422076befa028d2e26e408ae4af4c3a80a084"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
